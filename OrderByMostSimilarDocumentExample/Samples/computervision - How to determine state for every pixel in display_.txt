How to determine state for every pixel in display?
I'd like to point an array of cameras at a screen and determine the state of each pixel. This is definitely possible theoretically, but is it possible practically? From a theoretical perspective, I'd just calibrate all the cameras, undistort and dewarp the image, register individual pixels between images, and read out the results into an array. In fact, once you have a precise registration map of input vs. output pixels, there's no need to even do all the image transformations, it just winds up being a LUT. Practically, I'm not sure if this would be possible in any reasonable manner. Any number of issues, such as camera resolution, white balance, exposure, gamma correction, lighting characteristics, etc... could completely upend the process. But my hunch is that not, since if I take a picture of my computer screen it's... decent. It's not awesome, but it's not horrible either. And without spending much effort, I can get pretty decent pictures. This hints that it ought to be possible. I'm guessing someone has done this all before, and I'm just not googling with the right terminology. Thoughts? P.S. Bonus points for links to literature.  submitted by /u/kubark42 [link] [comments] 