AIRIS takes on an information incomplete game, MNIST, conceptual understanding, and knowledge transfer
AIRIS is my model-based reinforcement learning project. I've made a lot of progress in the last 6 months, including: A new, information incomplete version of the puzzle game environment. Now it can only see a small portion of the level at a time and must rely on modeling (or "remembering") off-screen elements to achieve its goal of collecting the batteries.  Testing it on MNIST number recognition. Unfortunately at this point I only tested it on 2k characters from the "Test" dataset because it took 2 weeks straight to get that far. I'll need to rework it to use parallel processing before I can feasibly do all 70k.  Demonstrating its ability to understand the elements of the puzzle game on a conceptual level. In other words, I showed it a few "tutorials" for how things like walls, doors / keys, etc... worked and it used that knowledge to breeze through levels it had never seen before.  Merging 2 agents trained on separate puzzle game elements into a 3rd agent that has the knowledge of both. Neither agent 1 nor agent 2 could complete the test level without significant experimentation to learn the elements they weren't trained on, but agent 3 completed it with no difficulty. I have experimented with this before, but that was before AIRIS was able to have a conceptual understanding of things so it wasn't as obvious that the knowledge was successfully combined to be used for novel problems.   I've got a bunch of demo gifs and more information on my dev blog: http://airis-ai.com/dev-blog/  submitted by /u/BerickCook [link] [comments] 