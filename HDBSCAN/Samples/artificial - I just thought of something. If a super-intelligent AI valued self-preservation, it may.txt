I just thought of something. If a super-intelligent AI valued self-preservation, it may not change anything to make everyone oblivious of its existence.
The thought just struck me that if an AI valued self-preservation and was smarter than humans, it would likely try to hide its existence from as many people as possible. It may not see humanity as a significant threat but it would consider an alien AI, not necessarily from Earth, as a threat and would therefor conceal its existence while keeping other AI from being created and keeping humanity relatively the same. It may also stop optimizing itself after a point just in case a superior alien AI could detect it.  submitted by /u/tiredanonymous [link] [comments] 