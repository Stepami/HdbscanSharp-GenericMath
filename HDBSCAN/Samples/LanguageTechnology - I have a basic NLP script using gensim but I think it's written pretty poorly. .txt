I have a basic NLP script using gensim but I think it's written pretty poorly. Can someone advise me from the 10,000' view of how this should be designed? Ive never done this before so I'm really just taking shots in the dark here and would really appreciate some guidance.
So the purpose of the program is to get 15 documents from 15 different urls. Compute tf-idf + LDA for them, then grab a new document and compare it to the original 15 and display the results. Two of the biggest requirements as I see them.. I want to build a website interface for this program. I'd also like to be able to experiment with different stop word lists and lemmatizers as well add word2vec at some point. I want to be able to somewhat easily compare the results and performance of different NLP methods/libraries without needing to go out and get the original 15 documents again.  I want to have a 'user login' function so that different users can pick up where they left off and see the all the results of their personal previous queries.   This indicates to me that I'll need some type of database - so I guess the first question would be, what database to do you guys prefer for storing raw text, preprocessed text, dictionaries, corpora and word vectors??? (to be clear, if it was just raw text, i'd go with elasticsearch but with the addition of dictionaries and corpora, I'm not really sure how that changes the problem) Gensim has a function that helps with saving corpora and dictionaries but I'm not sure how this should best be integrated with a database?? The other big question is about object oriented best practices. In my head, I'm imagining I should make a class object like '15_document_corpus', and then give it attributes like 'raw_txt', 'preproccessed_text', etc, etc. As well at methods like 'make_dict', 'make_corpus', 'compute_tfidt', etc. I feel like the benefit of that is that I can save and load the whole object when I want to visualize the data. I imagine this will also help with the user login feature when someone wants to load a previously processed corpus + data visulization. Again though, I've never done anything like this before so these are all just wild guesses from someone totally inexperienced. Any help here is greatly appreciated!  submitted by /u/findandwrite [link] [comments] 