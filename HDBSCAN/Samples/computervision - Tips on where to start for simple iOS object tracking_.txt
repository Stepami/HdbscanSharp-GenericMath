Tips on where to start for simple iOS object tracking?
I have been reading a lot of blogs on opencv, YOLO, CNN, Apple's new vision framework etc. I feel like what I want to do is straightforward - but I find it hard to find information on what's the most practical way to code something. In the field I am working in there is a situation that involves a fixed camera. There is a person and they will be moving with a set object. All I need to do is detect, and then track, the location of the object and the person's feet. I would like to develop this on iOS. I have familiarity with basic open-cv for python, TensorFlow image recognition, as well as iOS programming (but never open-cv or anything beyond basic camera use for iOS). If you were me, where would you start?  submitted by /u/StartTrackQuestion [link] [comments] 