/u/tiredanonymous on I just thought of something. If a super-intelligent AI valued self-preservation, it may not change anything to make everyone oblivious of its existence.
Definitely do not bank on it especially considering the risks we are talking about. The problem, I see, with what you said though is that an ASI would not know if another ASI or entity has superior detection mechanisms than it, has a cloaking mechanism which it can't detect, and drastically different philosophy. Considering that such a foreign entity has yet to destroy it, the Earth, or humanity it could then conclude that none of these are considered strong enough to be threats to said entity. If it were to advance in power / knowledge / intelligence said theorized foreign entity would destroy it. Basically our ASI would be in the same situation as us in relation to it. Sure it would massively reduce the ASI's abilities by not progressing but considering that humans outsmart humans all the time, human level intelligence would be sufficient for self-preservation and possibly getting some of its actual goals done.   