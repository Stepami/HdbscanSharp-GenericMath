Dealing with a gradient that's much larger for one parameter
I have a model that's essentially the additive sum of two other models. (It's VBPR, which takes the standard for implicit recommender systems (BPR) and adds a visual component.) If I take each component separately, i.e. the BPR section or the visual component, I get good results. However, if I combine them together, results drop. With very careful LR initialization/ annealing, I can get model AUC to 0.65. In contrast, the visual part alone gets to 0.68-0.73, and the non-visual part alone gets to 0.80+ without much effort. I think I've diagnosed the issue. There are 6 parameters total in this model, 3 for each part. One of the terms (visual) has a huge gradient, about 100x bigger than the rest of them. I believe this is why the model doesn't learn. The way the model is set up requires the other parameters to learn as well. My question is -- what's the simplest way to deal with this issue? I'm using vanilla gradient descent (implemented by hand). I believe this is what AdaGrad (and all the other extensions... AdaDelta, Adam, RMSProp) is designed to combat, but I'm wondering if there's anything I might be forgetting? Edit: I think there are some clarifications I need to make. 1) This model has very sparse updates. Essentially, data points are (user, item 1, item 2) tuples. 4 of the 6 parameters are vectors (or matrices) where an index corresponds to either a user or an item. I realized while implementing Adam these fancier update methods for neural nets won't work because the same item or user is very unlikely to be seen (for thousands of samples, on expectation). So using past history doesn't really help, especially since the exact same data point (i.e. the same user and two items) is pretty much never going to come up. 2) The issue with one parameter being too large is it essentially dictates the learning rate. If I use only the visual terms (which includes the one with a big gradient), I need to use a learning rate of ~0.007. But if I use only the non-visual terms, I can use a learning rate of 0.7. So if I use a LR of 0.7, the complete model doesn't learn; if I use a LR of 0.007, it learns but the other terms mostly are slow to update, so performance is dominated by how well that one parameter can predict individually (not that well). At this point, I'm going to go with /u/sritee and simply have different learning rates for each component. I think it's reasonable to make empirically (if dubious mathematically). If anyone has any suggestions, I'm all ears, but I can't think of anything better otherwise.  submitted by /u/askacadthrowaway [link] [comments] 