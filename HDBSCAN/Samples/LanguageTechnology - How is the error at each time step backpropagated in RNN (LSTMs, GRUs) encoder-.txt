How is the error at each time step backpropagated in RNN (LSTMs, GRUs) encoder-decoder architecture for machine translation?
My understanding: Assume we have encoded a sequence using RNN(lstm or gru). While decoding, decoder (RNN) will output some word at every time step. So at every time step we will have some error (since we have y_pred and y_true at time step t, let's say cross-entropy). If our output has length "k", then we have have "k" different error terms for a single training example with single pass through network. It would be great if someone could explain from this point. From here on, I am not able to understand how the error is backpropagated Some more specific doubts : At what time step does the backpropagation starts ? How many times weights of encoder and decoder are updated for a single pass, if we have "k" error terms corresponding to "k" time steps ?  submitted by /u/mundada [link] [comments] 