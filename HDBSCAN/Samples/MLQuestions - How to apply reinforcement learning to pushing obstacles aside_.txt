How to apply reinforcement learning to pushing obstacles aside.
Hi, I'm tasked with using a neural network (or another ML approach) to help alleviate the burden on a robotic planning problem in which the robot must grasp an object in a cluttered environment. The way it must do this is by pushing obstacles aside, provided a set of constraints (objects must not fall over, must not escape the work area etc.). Right now the algorithm samples trajectories then samples points of contact (with an associated force etc.) with any obstacles, running the proposed solutions through a physics simulator. My work is supposed to replace the physics simulator to make it more robust (so it doesn’t depend so heavily on initial parameters which are just guesses on our part, like the friction coefficient of the table) and to make it be able to generalize better. Since I have access to the simulator, I thought I could train a neural network with a given state, and a desired state as inputs and an action as the output, this action could then be compared with the one given by the simulator and thus we have a simple supervised learning problem. A second and more interesting stage would then involve learning with real robots in a real environment. It’s clear some kind of reinforcement learning is the way to go, but I have little experience and would like to ask for suggestionns. The problem I have is that we want to avoid sampling, so deep Q-Learning, which is what I’ve implemented in other projects, might not be applicable. Also, we can’t actually know what is the best action to take; the quality of the action will have to be measured indirectly by taking into account the obstacle’s displacement and other such factors. This also implies some kind of adaptation of the knowledge learned from the simulations will have to be translated, which is another problem. Thank you for reading this. Tldr: Any suggestions on how to approach a grasping problem in which a robot pushes aside obstacles without sampling?  submitted by /u/masters_student12 [link] [comments] 