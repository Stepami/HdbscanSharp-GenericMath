How exactly are multiple running processes managed on a single core, on an architectural level?
I hope these aren't taken as dumb or ill-formed questions, I have some background in programming, even MIPS assembly, but not a formal background besides what I messily take in myself. With a single set of registers and cache, how does a modern CPU manage 2 or more processes running at the same time without losing state for them? I can't imagine that it's being saved in main memory somewhere, which would be super costly. In that case, does multiple running processes have an effect on cache hit/miss chances for any single process? And how is CPU time delegated to processes, in a way that all running at the same time still manages to feel 'seamless', especially in cases where one program might not be very I/O bound if it's relatively small/simple (thus little opportunity for a context switch)? Obviously multithreading is a thing, but I guess I'm more curious about how multithreading works to address the problems I described (if they actually are problems). I'm hoping someone can point me in the right direction of filling in my lack of knowledge on microarchitectures, and potentially offer some explanation themselves.  submitted by /u/TheEyesightDim [link] [comments] 