[D] How to backprop this recursive sequential computational graph ?
Suppose we have a computational graph like this, how to correctly backprop gradients if we want to update policy parameters to reduce the total summed costs ? Should dynamics model and policy network accumulates gradients for each time the upward gradients comes in ? This can be decomposed into different cases as following: (For simplicity let us suppose only 2 time steps. ) Compute J = c1 + c2 Backward: 1.1): c1 -> dynamics model -> a0 -> policy 1.2): c2 -> dynamics model -> [a1, s1] where a1 -> policy and s1 -> dynamics -> a0 -> policy  The gradients of dynamics and policy accumulated for each time upward gradients passing through. i.e. after 1.1), both dynamics and policy have gradients. During 1.2): when firstly pass through dynamics, the gradients computed and added to old gradients (from 1.1) and so on. Backward pass for each time step: backward of c1 -> clean gradients of dynamics and policy -> backward of c2, then sum up the gradients of policy in each individual backwards.  Dynamics model not accumulating gradients, only to flow gradients when backward pass. But policy accumulate gradient.  Neither dynamics nor policy accumulates any gradients. e.g. for c2, the gradients only obtained when it reaches policy network which generates a0, all other passes of dynamics and policy, just compute local gradients and flow the gradients, not to add up gradients with their .grad.   It is a bit confused which might be the correct way to do it.  submitted by /u/xingdongrobotics [link] [comments] 