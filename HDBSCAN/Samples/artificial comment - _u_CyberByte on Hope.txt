/u/CyberByte on Hope
Bad data does indeed make it harder to learn good outcomes. If the errors are not systematic, the right behavior might still be learned. To some degree, many supervised learning and inverse reinforcement learning algorithms do this more or less automatically (to generalize they kind of need to smooth over some things anyway), but there are also more sophisticated methods for dealing with imperfect data. If errors are systematic, a good unbiased learning system would learn that bad behavior. To prevent this, you would need to put something in that can explicitly take those kinds of errors into account. Designing your system so that it will only learn good/desirable things in the wild can be quite a challenge.   