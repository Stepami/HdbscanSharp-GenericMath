/u/bale_mirth_control on Hope
Yes, maybe. But two popular examples immediately spring to mind. 1) Microsoft's Tay, which parroted nazi memes and was taken down quickly, and didn't seem to be all that sophisticated (wtf Microsoft?). 2) The Chinese chatbot that reportedly started spouting off about Chinese corruption and praising Western capitalism, i.e. mirroring what actual Chinese people (may) actually chat about. In both these cases the bot seemed to be following human bias but hopefully a general AI to come will be intelligent enough to discern human bias and avoid bait and politics. So, I wouldn't view it in so pessimistic terms. It's even possible that future generations of humans, presuming that general AI is some time off, will set a better example. I'll stick to my starry-eyed optimism, thank you.   