RFC on language Python package
I'm opening up some very basic low-level building blocks that I use for working with text data. It's intended to be used by code that processes text at scale and across many languages, so it doesn't pull in dependencies or large data files or do things that only work for English. Often it's simple, but it is not something that should be implemented inside a machine learning pipeline. For example, extracting n-grams from a string. The usefulness of char-level n-grams is appreciated more and more, especially for morphologically rich languages, which is most of them, especially for languages with fewer data, which is most of them, for all types of applications. And self-contained code for extracting char-level n-grams is easy to hack together: ng = lambda s, n: list(zip(*[s[i:] for i in range(n)])) ng('This is not a test.', 3)  But in practice we often only want n-grams within words, not across words. And it makes sense for that kind of code to be open and common, to have more features and more eyes on it, and fewer names and conventions. So I've put out the n-grams code in an initial release of the language Python package (GitHub | PyPI). pip install language  I am seeking feedback on what belongs in there, what does not, what the structure should be and any other tips on developing and maintaining an open-source NLP library. For now the basic structure is: language.languages (coming soon) Basic information on languages, for example equivalent and related ISO codes, and which chars are in which language. language.chars Mostly I want to expose and build on the unicodedata categories. For example, finer-grained categories for things like quotation marks, and some conservative canonicalisations. language.tokens Dumb but robust language-agnostic tokenisation. It should also take good guesses about so-called shapes - "3d", "1st", "https://youtube.com", "don't", "NamedEnt", "ACRNYM". language.ngrams Word- and char-level n-grams and associated operations like diffing and matching. Each submodule depends only on the previous ones.  submitted by /u/adammathias [link] [comments] 